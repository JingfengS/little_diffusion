import os
import torch
import logging
import numpy as np
from pathlib import Path
from typing import List, Optional, Union
from PIL import Image
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from diffusers import AutoencoderKL

logger = logging.getLogger(__name__)


class ImageDataset(Dataset):
    """
    å·¥ä¸šçº§å›¾ç‰‡æ•°æ®é›†ï¼š
    - é€’å½’æœç´¢
    - è‡ªåŠ¨è¿‡æ»¤éå›¾ç‰‡æ–‡ä»¶
    - ç»Ÿä¸€é¢„å¤„ç†æµæ°´çº¿
    - é”™è¯¯æ–‡ä»¶è‡ªåŠ¨è·³è¿‡ (è¿”å›ç©º)
    """

    def __init__(
        self,
        root_dir: Union[str, Path],
        image_size: int = 512,
        ext: List[str] = [".jpg", ".jpeg", ".png", ".webp", ".bmp"],
    ):
        self.root_dir = Path(root_dir)
        self.image_size = image_size
        self.files = sorted(
            [p for p in self.root_dir.rglob("*") if p.suffix.lower() in ext]
        )
        if len(self.files) == 0:
            logger.warning(f"âš ï¸ No images found in {root_dir}")
        # VAE æ ‡å‡†é¢„å¤„ç†: Resize -> Crop -> Normalize [-1, 1]
        self.transform = transforms.Compose(
            [
                transforms.Resize(
                    image_size, interpolation=transforms.InterpolationMode.LANCZOS
                ),
                transforms.CenterCrop(image_size),
                transforms.ToTensor(),
                transforms.Normalize([0.5], [0.5]),
            ]
        )

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        path = self.files[idx]
        try:
            img = Image.open(path).convert("RGB")
            return self.transform(img)
        except Exception as e:
            logger.error(f"âŒ Corrupted image {path}: {e}")
            # è¿”å› Noneï¼Œè¦åœ¨ collate_fn é‡Œå¤„ç†ï¼Œæˆ–è€…è¿™é‡Œè¿”å›å…¨é»‘å›¾
            # ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªæ ‡è®°ï¼Œè®© DataLoader è¿‡æ»¤ï¼ˆéœ€è¦è‡ªå®šä¹‰ collateï¼‰
            # è¿™é‡Œç®€å•è¿”å›å…¨ 0 Tensor å ä½ï¼Œé¿å…å´©æºƒ
            return torch.zeros(3, self.image_size, self.image_size)


class VAEProcessor:
    """
    VAE Engine for reuse
    """

    def __init__(self,
                 model_name: str = "stabilityai/sd-vae-ft-mse",
                 device: Optional[str] = None,
                 scaling_factor: float = 0.18215,
                 use_fp16: bool = True):
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.scaling_factor = scaling_factor
        self.use_fp16 = use_fp16 and (self.device != 'cpu')
        self.dtype = torch.float16 if self.use_fp16 else torch.float32
        logger.info(f"ğŸš€ Loading VAE: {model_name} (FP16: {self.use_fp16})")
        try:
            self.vae = AutoencoderKL.from_pretrained(model_name, torch_dtype=self.dtype).to(self.device)
            self.vae.eval()
            self.vae.requires_grad_(False) # å†»ç»“æƒé‡ï¼ŒèŠ‚çœæ˜¾å­˜

            # self.vae.enable_tiling()
        except Exception as e:
            logger.error(f"âŒ VAE Load Failed: {e}")
            raise e
    
    @torch.no_grad()
    def process_folder(self, input_dir: str, output_path: str, image_size: int = 512, batch_size: int = 4, num_workers: int = 4):
        """
        Process all images in a folder and save the latent representations.
        Save to .pt files
        """
        if os.path.dirname(output_path):
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

        dataset = ImageDataset(input_dir, image_size)
        if len(dataset) == 0:
            logger.warning(f"âš ï¸ No images found in {input_dir}")
            return None
        
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)
        
        all_latents = []
        logger.info(f"ğŸ“¸ Processing {len(dataset)} images from {input_dir}...")
        for batch in tqdm(dataloader, desc="Encoding"):
            pixel_values = batch.to(self.device, dtype=self.dtype)
            
            # Encode -> Sample -> Scale
            dist = self.vae.encode(pixel_values).latent_dist
            latents = dist.sample() * self.scaling_factor
            
            # ç«‹å³è½¬å› CPU é‡Šæ”¾æ˜¾å­˜
            all_latents.append(latents.float().cpu())
            
        # æ‹¼æ¥å¹¶ä¿å­˜
        final_tensor = torch.cat(all_latents, dim=0)
        torch.save(final_tensor, output_path)
        
        logger.info(f"âœ… Saved latents to {output_path}")
        logger.info(f"ğŸ“Š Shape: {final_tensor.shape} (N, 4, {image_size//8}, {image_size//8})")
        return final_tensor
    
    @torch.no_grad()
    def decode(self, latents: torch.Tensor) -> List[Image.Image]:
        """
        è§£ç  Latent Tensor å› PIL Images
        args:
            latents: (B, 4, H, W) Tensor
        returns:
            List of PIL Images
        """
        latents = latents.to(self.device, dtype=self.dtype)
        latents = latents / self.scaling_factor
        
        # VAE decoder
        image = self.vae.decode(latents).sample
        image = (image / 2 + 0.5).clamp(0, 1)
        
        # Convert to PIL Images
        image = image.cpu().permute(0, 2, 3, 1).float().numpy()
        
        output_images = []
        for i in range(image.shape[0]):
            img_np = (image[i] * 255).round().astype(np.uint8)
            output_images.append(Image.fromarray(img_np))
        
        return output_images