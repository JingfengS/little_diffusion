import os
import json
import hashlib
import logging
import torch
from pathlib import Path
from typing import List, Optional, Tuple
from PIL import Image
from tqdm import tqdm

# å¼•å…¥é¡¹ç›®ç»„ä»¶
from little_diffusion.dataset_pipeline.config import PipelineConfig, ImageMeta, CropType
from little_diffusion.dataset_pipeline.vision_ai import MattingEngine, FaceDetector
from little_diffusion.dataset_pipeline.transforms import WeightMapGenerator, SafeCropper

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s"
)
logger = logging.getLogger(__name__)


class ArknightsPipeline:
    def __init__(self, config: PipelineConfig = PipelineConfig()):
        self.config = config

        # 1. å‡†å¤‡ç›®å½•
        self.out_root = Path(config.processed_dir)
        self.img_dir = self.out_root / "images"
        self.mask_dir = self.out_root / "masks"
        self.img_dir.mkdir(parents=True, exist_ok=True)
        self.mask_dir.mkdir(parents=True, exist_ok=True)

        # 2. åŠ è½½ç™½åå•
        self.whitelist = []
        self.char_to_id = {}
        self._load_whitelist()

        # 3. åˆå§‹åŒ– AI å¼•æ“
        # æ³¨æ„ï¼šMattingEngine æ¯”è¾ƒåƒæ˜¾å­˜ï¼Œå»ºè®®å•è¿›ç¨‹è¿è¡Œ
        logger.info("ğŸ”§ Initializing AI Engines...")
        self.matting = MattingEngine(
            device="cuda" if torch.cuda.is_available() else "cpu"
        )
        self.face_detector = FaceDetector()
        self.weight_gen = WeightMapGenerator(
            fg_weight=config.weights.fg_weight,
            complex_bg_weight=config.weights.bg_complex_weight,
            pure_bg_weight=config.weights.bg_pure_weight,
        )
        logger.info("âœ… Engines Ready.")

    def _load_whitelist(self):
        path = Path(self.config.whitelist_path)
        if not path.exists():
            raise FileNotFoundError(f"Whitelist not found: {path}")
        with open(path, "r", encoding="utf-8") as f:
            self.whitelist = [line.strip() for line in f if line.strip()]
        # æŒ‰é•¿åº¦é™åºæ’åˆ—ï¼Œé˜²æ­¢"é™ˆ"åŒ¹é…åˆ°"å‡æ—¥å¨é¾™é™ˆ"
        self.whitelist.sort(key=len, reverse=True)
        self.char_to_id = {name: idx for idx, name in enumerate(self.whitelist)}
        logger.info(f"ğŸ“‹ Loaded {len(self.whitelist)} operators.")

    def _match_character(self, filename: str) -> Optional[str]:
        for kw in self.config.blacklist_keywords:
            if kw.upper() in filename.upper():
                return None
        for name in self.whitelist:
            if name in filename:
                return name
        return None

    def _save_pair(
        self, img: Image.Image, mask: Image.Image, base_name: str, suffix: str
    ) -> Tuple[str, str]:
        """ä¿å­˜ RGB å’Œ Mask å¯¹ï¼Œè¿”å›ç›¸å¯¹è·¯å¾„"""
        img_name = f"{base_name}_{suffix}.jpg"
        mask_name = f"{base_name}_{suffix}.png"  # Mask å­˜ä¸º PNG æ— æŸç°åº¦

        img.save(self.img_dir / img_name, quality=95)
        mask.save(self.mask_dir / mask_name)

        return f"images/{img_name}", f"masks/{mask_name}"

    def process_single_file(self, file_path: Path, char_name: str) -> List[ImageMeta]:
        results = []
        label_id = self.char_to_id[char_name]

        try:
            # 1. åŠ è½½åŸå›¾
            with Image.open(file_path) as raw_img:
                raw_img = raw_img.convert("RGBA")

                # ğŸ”™ å›æ»šé€»è¾‘ï¼šä½¿ç”¨åŸå›¾çš„ bbox (ä¿ç•™ç‰¹æ•ˆ/èƒŒæ™¯)ï¼Œè€Œä¸æ˜¯ AI Mask çš„ bbox
                # è¿™æ · Full Body å°±ä¼šåŒ…å«å…‰ç¿¼ã€æ›¿èº«ã€åºŸå¢Ÿç­‰å…ƒç´ ï¼Œä¿æŒå¤šæ ·æ€§
                bbox = raw_img.getbbox()
                if not bbox:
                    return []
                img_trimmed = raw_img.crop(bbox)

            # 2. AI ä»‹å…¥
            # è™½ç„¶æˆ‘ä»¬ä¿ç•™äº†èƒŒæ™¯ï¼Œä½†æˆ‘ä»¬ä¾ç„¶éœ€è¦ AI å‘Šè¯‰æˆ‘ä»¬â€œå“ªé‡Œæ˜¯äººâ€
            # ç”¨äºç”Ÿæˆ Weight Map (äºº=1.0, èƒŒæ™¯ç‰¹æ•ˆ=0.1)
            ai_mask = self.matting.get_alpha_mask(img_trimmed)
            weight_map = self.weight_gen.generate(img_trimmed, ai_mask)

            # 3. åˆæˆç™½åº•å›¾
            rgb_white_bg = Image.new("RGB", img_trimmed.size, (255, 255, 255))
            rgb_white_bg.paste(img_trimmed, mask=img_trimmed.split()[3])

            # å‡†å¤‡åŸºç¡€ä¿¡æ¯
            file_hash = hashlib.md5(str(file_path).encode("utf-8")).hexdigest()[:6]
            base_name = f"{label_id}_{char_name}_{file_hash}"
            w, h = rgb_white_bg.size

            # ğŸ”¥ é¢„å…ˆæ£€æµ‹äººè„¸ (æœåŠ¡äº Face å’Œ Half ç­–ç•¥)
            face_box = self.face_detector.get_best_face_box(rgb_white_bg)
            if face_box:
                fx1, fy1, fx2, fy2 = face_box
                face_cx = (fx1 + fx2) / 2
                face_cy = (fy1 + fy2) / 2
                face_h = fy2 - fy1
            else:
                face_cx = w / 2
                face_cy = h * 0.2
                face_h = h * 0.1

            # ================= ç­–ç•¥ A: Full Body (ç­‰æ¯”ç¼©æ”¾) =================
            scale = (self.config.target_pixel_area / (w * h)) ** 0.5
            if scale < 1.0:
                target_w, target_h = int(w * scale), int(h * scale)
                img_full = rgb_white_bg.resize(
                    (target_w, target_h), Image.Resampling.LANCZOS
                )
                # âš ï¸ Mask å¿…é¡»åŒæ­¥ç¼©æ”¾
                mask_full = weight_map.resize(
                    (target_w, target_h), Image.Resampling.NEAREST
                )
            else:
                img_full = rgb_white_bg
                mask_full = weight_map

            p_img, p_mask = self._save_pair(
                img_full, mask_full, base_name, CropType.FULL.value
            )
            results.append(
                ImageMeta(
                    p_img,
                    p_mask,
                    char_name,
                    label_id,
                    CropType.FULL.value,
                    str(file_path),
                )
            )

            # ================= ç­–ç•¥ B: Face Crop (æ™ºèƒ½å¤§å¤´ç…§) =================
            # ä½¿ç”¨ FaceDetector åœ¨ RGB å›¾ä¸Šæ‰¾è„¸
            if face_box:
                # æ‰©å›¾é€»è¾‘ (2.0å€ï¼ŒåŒ…å«å¤´å‘)
                cx, cy = (fx1 + fx2) / 2, (fy1 + fy2) / 2
                span = max(fx2 - fx1, fy2 - fy1) * 2.0
                span = max(span, 512)  # æœ€å°å°ºå¯¸é™åˆ¶
                half_span = span / 2
                crop_box = (
                    cx - half_span,
                    cy - half_span,
                    cx + half_span,
                    cy + half_span,
                )  # å¯èƒ½è¶…ç•Œ

                # ä½¿ç”¨ SafeCropper åŒæ­¥è£å‰ª RGB å’Œ Weight Map
                img_face = SafeCropper.crop_and_pad(
                    rgb_white_bg, crop_box, fill_color=(255, 255, 255)
                )
                mask_face = SafeCropper.crop_and_pad(
                    weight_map,
                    crop_box,
                    fill_color=int(self.config.weights.bg_complex_weight * 255),
                )
                # Mask å¡«å……é»˜è®¤ç»™å¤æ‚èƒŒæ™¯æƒé‡ï¼Œæ¯”è¾ƒå®‰å…¨

                # ç»Ÿä¸€ Resize åˆ° 768x768
                target_s = self.config.face_crop_size
                img_face = img_face.resize(
                    (target_s, target_s), Image.Resampling.LANCZOS
                )
                mask_face = mask_face.resize(
                    (target_s, target_s), Image.Resampling.NEAREST
                )

                p_img, p_mask = self._save_pair(
                    img_face, mask_face, base_name, CropType.FACE.value
                )
                results.append(
                    ImageMeta(
                        p_img,
                        p_mask,
                        char_name,
                        label_id,
                        CropType.FACE.value,
                        str(file_path),
                    )
                )

            # ================= ç­–ç•¥ C: Half Body (Letterbox) =================
            target_w_final, target_h_final = self.config.half_body_size
            target_ar = target_w_final / target_h_final  # 0.75

            if face_box:
                # 1. ç¡®å®š Top: å¤´é¡¶å‘ä¸Šç•™ 1.2 å€è„¸é•¿ (å¤Ÿæ”¾å…‰ç¯/è€³æœµ)
                #    max(0, ...) é˜²æ­¢åˆ‡å‡ºä¸Šè¾¹ç•Œ
                crop_top = int(max(0, fy1 - face_h * 1.2))

                # 2. ç¡®å®š Bottom: å¤´åº•å‘ä¸‹å»¶ä¼¸ 6.5 å€è„¸é•¿ (Head + Body + Thighs)
                #    min(h, ...) é˜²æ­¢åˆ‡å‡ºä¸‹è¾¹ç•Œ
                #    æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å®é™…ä¸Šæ˜¯åœ¨å®šä¹‰ä¸€ä¸ªâ€œç†æƒ³çš„åŠèº«é«˜åº¦â€
                ideal_bottom = int(fy2 + face_h * 6.5)
                crop_bottom = int(min(h, ideal_bottom))

                # 3. ç¡®å®šæœ€ç»ˆé«˜åº¦
                crop_h = crop_bottom - crop_top

                # å¦‚æœè„¸å¤ªå°æˆ–è€…è®¡ç®—å‡ºçš„é«˜åº¦å¤ªå°ï¼Œå¼ºè¡Œä¿åº• (é˜²æ­¢åˆ‡å‡ºæå°çš„å›¾)
                if crop_h < 512:
                    crop_h = int(min(h, 1024))
                    crop_bottom = crop_top + crop_h
            else:
                # Fallback: å¦‚æœæ²¡è„¸ï¼Œå›é€€åˆ°åŸæ¥çš„é€»è¾‘ (Top 0, Height 60%)
                crop_top = 0
                crop_h = int(h * 0.6)
                crop_bottom = crop_h

            # 4. æ ¹æ®é«˜åº¦å’Œæ¯”ä¾‹ (3:4) åæ¨å®½åº¦
            crop_w = int(crop_h * target_ar)

            # 5. ç¡®å®šå·¦å³è¾¹ç•Œ (ä»¥äººè„¸/ä¸­å¿ƒä¸ºè½´)
            half_crop_w = crop_w / 2
            left = int(face_cx - half_crop_w)
            right = int(face_cx + half_crop_w)

            # 6. è¾¹ç•Œä¿®æ­£ (Shift & Clamp)
            if left < 0:
                right -= left
                left = 0
            if right > w:
                left -= right - w
                right = w
                if left < 0:
                    left = 0

            # 7. æ‰§è¡Œè£å‰ª
            img_half = rgb_white_bg.crop((left, crop_top, right, crop_bottom))
            mask_half = weight_map.crop((left, crop_top, right, crop_bottom))

            # 8. Resize (ä¿æŒçºµæ¨ªæ¯”ï¼Œå®½åº¦ä¸è¶³è¡¥ç™½è¾¹)
            scale_h = target_h_final / img_half.height
            new_w_res = int(img_half.width * scale_h)

            img_half_res = img_half.resize(
                (new_w_res, target_h_final), Image.Resampling.LANCZOS
            )
            mask_half_res = mask_half.resize(
                (new_w_res, target_h_final), Image.Resampling.NEAREST
            )

            final_img = Image.new(
                "RGB", (target_w_final, target_h_final), (255, 255, 255)
            )
            final_mask = Image.new(
                "L",
                (target_w_final, target_h_final),
                int(self.config.weights.bg_pure_weight * 255),
            )

            paste_x = (target_w_final - new_w_res) // 2
            final_img.paste(img_half_res, (paste_x, 0))
            final_mask.paste(mask_half_res, (paste_x, 0))

            p_img, p_mask = self._save_pair(
                final_img, final_mask, base_name, CropType.HALF.value
            )
            results.append(
                ImageMeta(
                    p_img,
                    p_mask,
                    char_name,
                    label_id,
                    CropType.HALF.value,
                    str(file_path),
                )
            )

        except Exception as e:
            logger.error(f"âŒ Error processing {file_path}: {e}")
            # å‡ºé”™æ—¶ä¸ä¸­æ–­ï¼Œç›´æ¥è¿”å›ç©º
            return []

        return results

    def run(self):
        logger.info(f"ğŸš€ Starting Data Pipeline")
        logger.info(f"   Source: {self.config.raw_dir}")
        logger.info(f"   Target: {self.config.processed_dir}")

        # 1. æ‰«ææ–‡ä»¶
        tasks = []
        raw_path = Path(self.config.raw_dir)
        for root, _, files in os.walk(raw_path):
            if any(kw in root for kw in self.config.blacklist_keywords):
                continue

            for file in files:
                if Path(file).suffix not in self.config.allowed_extensions:
                    continue
                char_name = self._match_character(file)
                if char_name:
                    tasks.append((Path(root) / file, char_name))

        logger.info(f"ğŸ” Found {len(tasks)} valid images.")

        # 2. é¡ºåºæ‰§è¡Œ (GPU Matting éš¾ä»¥å¹¶è¡Œï¼Œä¸” Python GIL é™åˆ¶)
        # å¦‚æœéœ€è¦åŠ é€Ÿï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ PyTorch DataLoader çš„å¤šè¿›ç¨‹æ¨¡å¼ï¼Œä½†è¿™é‡Œç®€å•èµ·è§ç”¨å¾ªç¯
        all_meta = []
        for file_path, char_name in tqdm(tasks, desc="Processing"):
            metas = self.process_single_file(file_path, char_name)
            all_meta.extend(metas)

        # 3. ä¿å­˜ç´¢å¼•
        logger.info("ğŸ’¾ Saving Dataset Metadata...")
        meta_dicts = [m.__dict__ for m in all_meta]
        with open(self.out_root / "dataset.json", "w", encoding="utf-8") as f:
            json.dump(meta_dicts, f, indent=2, ensure_ascii=False)

        with open(self.out_root / "id_map.json", "w", encoding="utf-8") as f:
            json.dump(self.char_to_id, f, indent=2, ensure_ascii=False)

        logger.info("âœ¨ Data Pipeline Completed Successfully!")


if __name__ == "__main__":
    pipeline = ArknightsPipeline()
    pipeline.run()
