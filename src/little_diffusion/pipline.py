import torch
import numpy as np
from PIL import Image
from tqdm import tqdm
from typing import Optional, Tuple

# å¼•å…¥ä½ çš„ç»„ä»¶
from little_diffusion.core import ODE, EulerSimulator
from little_diffusion.processor import VAEProcessor

class LatentDiffusionPipe:
    """
    ğŸŒŸ å·¥ä¸šçº§æ¨ç†æµæ°´çº¿ (Inference Pipeline)
    è´Ÿè´£æŠŠ Model, VAE, Scheduler ä¸²èµ·æ¥ï¼Œå®ç°ä¸€é”®å‡ºå›¾ã€‚
    """
    def __init__(
        self, 
        model: torch.nn.Module, 
        vae_processor: VAEProcessor, 
        device: str = "cuda"
    ):
        self.model = model.to(device)
        self.vae_processor = vae_processor
        self.device = device
        self.model.eval()

    @torch.no_grad()
    def __call__(
        self, 
        steps: int = 50, 
        batch_size: int = 1, 
        seed: Optional[int] = None,
        image_size: int = 704
    ) -> Image.Image:
        """
        ğŸ¨ ä¸€é”®ç”Ÿæˆå›¾ç‰‡
        Args:
            steps: é‡‡æ ·æ­¥æ•° (è¶Šé«˜ç”»è´¨è¶Šå¥½ï¼Œä½†æ›´æ…¢)
            batch_size: ä¸€æ¬¡ç”Ÿæˆå‡ å¼ 
            seed: éšæœºç§å­ (å¤ç°ç”¨)
            image_size: è¾“å‡ºåˆ†è¾¨ç‡ (pixel)
        Returns:
            PIL Image å¯¹è±¡ (å¦‚æœ batch_size > 1ï¼Œè¿”å›åˆ—è¡¨)
        """
        # 1. è®¾å®šéšæœºç§å­ (ä¸ºäº†å¤ç°é‚£å¼ â€œæ¢¦ä¸­æƒ…å›¾â€)
        if seed is not None:
            torch.manual_seed(seed)
            np.random.seed(seed)
        
        # 2. å‡†å¤‡ Latent å™ªå£° (x0)
        # Latent å°ºå¯¸ = å›¾ç‰‡å°ºå¯¸ / 8
        latent_dim = image_size // 8
        # Shape: (B, 4, H, W)
        x_init = torch.randn(batch_size, 4, latent_dim, latent_dim).to(self.device)
        
        # 3. å‡†å¤‡æ—¶é—´æ­¥ (Time Steps)
        # ä» 0 (çº¯å™ªå£°) -> 1 (æ•°æ®)
        # Shape: (B, Steps, 1) æ–¹ä¾¿å¹¿æ’­è®¡ç®—
        ts = torch.linspace(0, 1, steps, device=self.device).view(1, -1, 1).expand(batch_size, steps, 1)

        # 4. å®šä¹‰ ODE æ±‚è§£å™¨
        # å®šä¹‰ drift å‡½æ•°: v = model(x, t)
        def drift_func(x, t):
            # ç¡®ä¿ t çš„å½¢çŠ¶é€‚é… model
            if t.dim() == 1: t = t.view(-1, 1)
            # âš¡ï¸ 5070 Ti æ··åˆç²¾åº¦åŠ é€Ÿ
            with torch.amp.autocast('cuda'):
                return self.model(x, t)

        # è¿™é‡Œçš„ ODE ç±»æˆ‘ä»¬å¯ä»¥ç®€åŒ–ä¸ºä¸€ä¸ª lambda æˆ–è€…åŒ…è£…å™¨
        # ä¸ºäº†å¤ç”¨ä½ ç°æœ‰çš„æ¶æ„ï¼Œæˆ‘ä»¬åŠ¨æ€æ„å»ºä¸€ä¸ªç®€å•çš„ ODE å¯¹è±¡
        class SimpleODE(ODE):
            def drift_coefficient(self, x, t):
                return drift_func(x, t)

        ode = SimpleODE()
        simulator = EulerSimulator(ode)

        # 5. ğŸš€ æ‰§è¡Œé‡‡æ · (ä¹Ÿå°±æ˜¯ä½ è´´çš„é‚£æ®µä»£ç !)
        # æˆ‘ä»¬åœ¨è¿™é‡ŒåŠ ä¸ª tqdm è¿›åº¦æ¡ï¼Œè®©ç”¨æˆ·çŸ¥é“è¿˜è¦ç­‰å¤šä¹…
        print(f"ğŸ¨ Generating {image_size}x{image_size} image with {steps} steps...")
        
        # ç›´æ¥è°ƒç”¨ simulate (åªè¿”å›æœ€ç»ˆç»“æœï¼Œä¸å­˜è½¨è¿¹)
        # æ³¨æ„ï¼šä¸ºäº†è®© tqdm ç”Ÿæ•ˆï¼Œæˆ‘ä»¬éœ€è¦ç¨å¾®é­”æ”¹ä¸€ä¸‹ simulate æˆ–è€…åœ¨è¿™é‡Œæ‰‹åŠ¨å†™å¾ªç¯
        # ä¸ºäº†å®Œå…¨å¤ç”¨ä½ çš„ simulate ä»£ç ï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨å®ƒï¼š
        latents = simulator.simulate(x_init, ts)
        
        # 6. âœ¨ VAE è§£ç  (Latent -> Pixel)
        print("ğŸ§© Decoding...")
        images = self.vae_processor.decode(latents)
        
        # å¦‚æœåªæœ‰ä¸€å¼ å›¾ï¼Œç›´æ¥è¿”å›å¯¹è±¡ï¼Œè€Œä¸æ˜¯åˆ—è¡¨
        if batch_size == 1:
            return images[0]
        return images