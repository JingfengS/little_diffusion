import os
import logging
import torch
import numpy as np
import torch.nn.functional as F
from typing import List, Optional
from PIL import Image
from tqdm import tqdm
from torch.utils.data import DataLoader
from diffusers import AutoencoderKL

from little_diffusion.preprocessing.dataset import JSONImageDataset

logger = logging.getLogger(__name__)

class VAEProcessor:
    def __init__(
        self,
        model_name: str = "madebyollin/sdxl-vae-fp16-fix",
        device: Optional[str] = None,
        scaling_factor: float = 0.13025,
        use_fp16: bool = True,
    ):
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.scaling_factor = scaling_factor
        
        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç²¾åº¦
        if use_fp16 and self.device != "cpu":
            if torch.cuda.is_bf16_supported():
                self.dtype = torch.bfloat16
            else:
                self.dtype = torch.float16
        else:
            self.dtype = torch.float32

        logger.info(f"ğŸš€ Loading VAE: {model_name} ({self.dtype})")
        try:
            self.vae = AutoencoderKL.from_pretrained(
                model_name, torch_dtype=self.dtype
            ).to(self.device)
            self.vae.eval()
            self.vae.requires_grad_(False)
        except Exception as e:
            logger.error(f"âŒ VAE Load Failed: {e}")
            raise e

    @torch.no_grad()
    def process_dataset(
        self,
        metadata_path: str,
        image_root: str,
        output_path: str,
        image_size: int = 1024,
        batch_size: int = 4,
        num_workers: int = 4,
    ):
        if os.path.dirname(output_path):
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

        dataset = JSONImageDataset(metadata_path, image_root, image_size)
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=True,
        )

        all_latents = []
        all_masks = [] 
        all_labels = []

        logger.info("ğŸ“¸ Starting VAE Encoding & Mask Downsampling...")

        for batch_imgs, batch_masks, batch_labels in tqdm(dataloader, desc="Encoding"):
            # Move to GPU
            pixel_values = batch_imgs.to(self.device, dtype=self.dtype)
            
            # Mask ä¸éœ€è¦è½¬ fp16ï¼Œä¿æŒ float32 ç²¾åº¦æ›´å¥½ï¼Œæˆ–è€…è·Ÿ latent ä¿æŒä¸€è‡´ä¹Ÿå¯ä»¥
            # è¿™é‡Œä¸ºäº† avg_pool è®¡ç®—å‡†ç¡®ï¼Œå»ºè®®ç”¨ float32 è®¡ç®—ï¼Œæœ€åå­˜çš„æ—¶å€™å¯ä»¥å‹ç¼©
            batch_masks = batch_masks.to(self.device)

            # 1. VAE ç¼–ç  RGB å›¾åƒ
            dist = self.vae.encode(pixel_values).latent_dist
            latents = dist.sample() * self.scaling_factor

            # 2. Mask ä¸‹é‡‡æ ·ï¼(1024x1024 -> 128x128)
            # ä½¿ç”¨ Average Pooling è·å¾—å¹³æ»‘è¾¹ç¼˜
            masks_downsampled = F.avg_pool2d(batch_masks, kernel_size=8, stride=8)

            # 3. æ¬å› CPU
            all_latents.append(latents.float().cpu())
            all_masks.append(masks_downsampled.float().cpu())
            all_labels.append(batch_labels.long().cpu())

        final_latents = torch.cat(all_latents, dim=0)
        final_masks = torch.cat(all_masks, dim=0)
        final_labels = torch.cat(all_labels, dim=0)

        # æ‰“åŒ…ä¿å­˜
        payload = {
            "latents": final_latents,
            "masks": final_masks,
            "labels": final_labels,
            "scaling_factor": self.scaling_factor,
            "image_size": image_size,
            "latent_size": final_latents.shape[-1],
        }

        torch.save(payload, output_path)

        logger.info(f"âœ… Saved processed data to {output_path}")
        logger.info(f"ğŸ“Š Latents Shape: {final_latents.shape}")
        logger.info(f"ğŸ­ Masks Shape: {final_masks.shape}")
        logger.info(f"ğŸ·ï¸ Labels Shape: {final_labels.shape}")

    @torch.no_grad()
    def decode(self, latents: torch.Tensor) -> List[Image.Image]:
        """è§£ç å·¥å…· (ç”¨äº Sample é˜¶æ®µ)"""
        latents = latents.to(self.device, dtype=self.dtype)
        latents = latents / self.scaling_factor

        image = self.vae.decode(latents).sample
        image = (image / 2 + 0.5).clamp(0, 1)
        image = image.cpu().permute(0, 2, 3, 1).float().numpy()

        output_images = []
        for i in range(image.shape[0]):
            img_np = (image[i] * 255).round().astype(np.uint8)
            output_images.append(Image.fromarray(img_np))

        return output_images