import os
import hashlib
import logging
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path
from typing import List, Dict, Optional, Union, Set, Tuple
from concurrent.futures import ProcessPoolExecutor, as_completed
import json

from PIL import Image
from tqdm import tqdm

# é…ç½® Logger
logger = logging.getLogger(__name__)

# =========================================================
# ğŸ”„ ä¾èµ–åˆ‡æ¢: dghs-imgutils
# =========================================================
try:
    from imgutils.detect import detect_faces

    HAS_IMGUTILS = True
except ImportError:
    HAS_IMGUTILS = False
    logger.warning(
        "âš ï¸ dghs-imgutils not found. Install it for SOTA cropping: pip install dghs-imgutils[opencv]"
    )


class CropType(Enum):
    """å®šä¹‰è£å‰ªç±»å‹çš„æšä¸¾ï¼Œé˜²æ­¢é­”æ³•å­—ç¬¦ä¸²"""

    FULL = "full"
    FACE = "face"
    HALF = "half"


@dataclass
class PreprocessConfig:
    """
    é…ç½®ç±»ï¼šå°†æ‰€æœ‰ç¡¬ç¼–ç å‚æ•°æå–å‡ºæ¥
    """

    target_pixel_area: int = 1024 * 1024  # ç›®æ ‡åƒç´ é‡ (1MP)
    face_crop_size: int = 768  # å¤§å¤´ç…§å°ºå¯¸
    half_body_size: Tuple[int, int] = (768, 1024)  # åŠèº«ç…§å°ºå¯¸

    # é»‘åå•ï¼šé‡åˆ°è¿™äº›è¯ç›´æ¥è·³è¿‡
    blacklist_keywords: List[str] = field(
        default_factory=lambda: [
            "NPC",
            "IMG",
            "avg",
            "æ€ªç‰©",
            "æ•Œæ–¹",
            "token",
            "trap",
            "æ•´åˆè¿åŠ¨",
            "é¾™é—¨å£«å…µ",
            "è·¯äºº",
            "é»‘å¸®",
            "ä¿é•–",
            "æ¸¸å®¢",
            "äººç‰©ä»‹ç»",
            "å°è½¦",
        ]
    )

    # å…è®¸çš„æ–‡ä»¶æ‰©å±•å
    allowed_extensions: Set[str] = field(
        default_factory=lambda: {".png", ".jpg", ".jpeg", ".PNG", ".JPG"}
    )


@dataclass
class ImageMeta:
    """
    æ•°æ®ä¼ è¾“å¯¹è±¡ (DTO)ï¼Œç¡®ä¿ dataset.json çš„ç»“æ„ç¨³å®š
    """

    file_path: str  # ç›¸å¯¹è·¯å¾„
    character: str  # è§’è‰²å
    class_id: int  # æ•°å­— ID
    type: str  # è£å‰ªç±»å‹
    original_path: str  # æº¯æºè·¯å¾„


class ArknightsPreprocessor:
    """
    æ˜æ—¥æ–¹èˆŸç«‹ç»˜ä¸“ç”¨ ETL å¤„ç†å™¨
    Extract: é€’å½’æ‰«æ
    Transform: æ™ºèƒ½è£å‰ªã€ç¼©æ”¾ã€å»èƒŒ
    Load: ä¿å­˜ä¸ºæ‰å¹³åŒ–æ•°æ®é›†
    """

    def __init__(self, config: PreprocessConfig = PreprocessConfig()):
        self.config = config
        self.whitelist: List[str] = []
        self.char_to_id: Dict[str, int] = {}

    def load_whitelist(self, txt_path: Union[str, Path]) -> None:
        """åŠ è½½ç™½åå•å¹¶æ„å»ºIDæ˜ å°„"""
        path = Path(txt_path)
        if not path.exists():
            raise FileNotFoundError(f"Whitelist file not found: {path}")
        with open(path, "r", encoding="utf-8") as f:
            names = [line.strip() for line in f if line.strip()]
            self.whitelist = sorted(list(set(names)), key=len, reverse=True)

        self.char_to_id = {name: idx for idx, name in enumerate(self.whitelist)}
        logger.info(f"ğŸ“‹ Loaded {len(self.whitelist)} operators from whitelist.")

    def _is_blacklisted(self, image_path_str: str) -> bool:
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ…å«é»‘åå•å…³é”®è¯"""
        # ç»Ÿä¸€è½¬å¤§å†™æ¯”è¾ƒï¼Œå¿½ç•¥å¤§å°å†™å·®å¼‚
        path_upper = image_path_str.upper()
        return any(kw.upper() in path_upper for kw in self.config.blacklist_keywords)

    def _match_character_name(self, filename: str) -> Optional[str]:
        """æ ¸å¿ƒåŒ¹é…é€»è¾‘ï¼šä»æ–‡ä»¶åä¸­æå–è§’è‰²å"""
        for name in self.whitelist:
            if name in filename:
                return name
        return None

    def _get_smart_face_crop(self, img_pil: Image.Image) -> Image.Image:
        """
        AI æ™ºèƒ½è£å‰ªæ ¸å¿ƒé€»è¾‘ (dghs-imgutils ç‰ˆæœ¬)
        """
        w, h = img_pil.size
        face_box = None

        if HAS_IMGUTILS:
            # detect_faces è¿”å›åˆ—è¡¨: [((x0, y0, x1, y1), label, score), ...]
            # æˆ‘ä»¬åªéœ€è¦æ£€æµ‹äººè„¸ (labelé€šå¸¸ä¸éœ€è¦è¿‡æ»¤ï¼Œé»˜è®¤å°±æ˜¯è„¸)
            try:
                detections = detect_faces(img_pil)

                if detections:
                    # 1. æ’åºï¼šå–ç½®ä¿¡åº¦(score)æœ€é«˜çš„é‚£å¼ è„¸
                    # dghsçš„è¿”å›æ ¼å¼æ˜¯ ((x0, y0, x1, y1), label, score)
                    best_face = max(detections, key=lambda x: x[2])
                    (fx1, fy1, fx2, fy2), _, score = best_face

                    # åªæœ‰ç½®ä¿¡åº¦å¤Ÿé«˜æ‰ä¿¡å®ƒ (æ¯”å¦‚ > 0.5)
                    if score > 0.5:
                        face_w = fx2 - fx1
                        face_h = fy2 - fy1

                        cx = fx1 + face_w / 2
                        cy = fy1 + face_h / 2

                        # ğŸŒŸ æ‰©å›¾å€æ•° (Zoom Out Factor)
                        # 2.2x - 2.5x èƒ½åŒ…å«å¤´å‘å’Œè„–å­
                        crop_span = max(face_w, face_h) * 2.0

                        # é™åˆ¶æœ€å°å°ºå¯¸ï¼Œé˜²æ­¢åˆ‡å¤ªå°æ”¾å¤§åæ¨¡ç³Š
                        crop_span = max(crop_span, 512)

                        half_span = crop_span / 2

                        left = max(0, cx - half_span)
                        top = max(0, cy - half_span)
                        right = min(w, cx + half_span)
                        bottom = min(h, cy + half_span)

                        # è¾¹ç•Œä¿®æ­£ï¼šå°½é‡ä¿æŒæ­£æ–¹å½¢
                        if right - left < crop_span:  # å®½ä¸å¤Ÿ
                            if left == 0:
                                right = min(w, crop_span)
                            else:
                                left = max(0, w - crop_span)
                        if bottom - top < crop_span:  # é«˜ä¸å¤Ÿ
                            if top == 0:
                                bottom = min(h, crop_span)
                            else:
                                top = max(0, h - crop_span)

                        face_box = (left, top, right, bottom)
            except Exception as e:
                logger.warning(f"Face detection failed: {e}")

        # Fallback: å¦‚æœæ²¡è£…åº“ï¼Œæˆ–è€…æ²¡æ£€æµ‹åˆ°è„¸ï¼Œä½¿ç”¨è§„åˆ™è£å‰ª
        if face_box is None:
            crop_size = min(int(h * 0.45), w)
            center_x = w // 2
            left = max(0, center_x - crop_size // 2)
            top = int(h * 0.05)
            face_box = (left, top, left + crop_size, top + crop_size)

        return img_pil.crop(face_box)

    def _process_single_image(
        self, img_path: Path, output_dir: Path, char_name: str
    ) -> List[ImageMeta]:
        # ... (è¿™éƒ¨åˆ†é€»è¾‘ä¸ä¹‹å‰å®Œå…¨ä¸€è‡´ï¼Œä¿æŒ Letterbox å’Œ 3ç§è£å‰ªç­–ç•¥ä¸å˜) ...
        # ... ä¸ºäº†èŠ‚çœç¯‡å¹…ï¼Œè¿™é‡Œå¯ä»¥ç›´æ¥å¤åˆ¶ä¸Šä¸€æ¬¡å›ç­”ä¸­çš„ _process_single_image ä»£ç  ...
        # ... å”¯ä¸€çš„åŒºåˆ«æ˜¯ _process_single_image å†…éƒ¨è°ƒç”¨çš„æ˜¯ self._get_smart_face_crop ...

        label_id = self.char_to_id[char_name]
        results = []

        try:
            # 1. Load & Trim
            with Image.open(img_path) as img:
                img = img.convert("RGBA")
                bbox = img.getbbox()
                if bbox is None:
                    return []
                img_trimmed = img.crop(bbox)

            # 2. Composite White Background
            full_bg = Image.new("RGB", img_trimmed.size, (255, 255, 255))
            full_bg.paste(img_trimmed, mask=img_trimmed.split()[3])

            file_hash = hashlib.md5(str(img_path).encode("utf-8")).hexdigest()[:6]
            base_name = f"{label_id}_{char_name}_{file_hash}"
            w, h = full_bg.size

            # === A. Full Body ===
            scale = (self.config.target_pixel_area / (w * h)) ** 0.5
            if scale < 1.0:
                img_full = full_bg.resize(
                    (int(w * scale), int(h * scale)), Image.Resampling.LANCZOS
                )
            else:
                img_full = full_bg
            full_name = f"{base_name}_{CropType.FULL.value}.jpg"
            img_full.save(output_dir / full_name, quality=95)
            results.append(
                ImageMeta(
                    full_name, char_name, label_id, CropType.FULL.value, str(img_path)
                )
            )

            # === B. Face Crop (ä½¿ç”¨æ–°ç‰ˆ dghs é€»è¾‘) ===
            img_face_raw = self._get_smart_face_crop(full_bg)
            img_face = img_face_raw.resize(
                (self.config.face_crop_size, self.config.face_crop_size),
                Image.Resampling.LANCZOS,
            )
            face_name = f"{base_name}_{CropType.FACE.value}.jpg"
            img_face.save(output_dir / face_name, quality=95)
            results.append(
                ImageMeta(
                    face_name, char_name, label_id, CropType.FACE.value, str(img_path)
                )
            )

            # === C. Half Body (ä½¿ç”¨ Letterbox é€»è¾‘) ===
            half_crop_h = int(h * 0.55)
            target_ar = 3 / 4
            current_ar = w / half_crop_h

            crop_w = w
            crop_h = half_crop_h

            if current_ar > target_ar:
                target_crop_w = int(crop_h * target_ar)
                left = (w - target_crop_w) // 2
                crop_w = target_crop_w
            else:
                left = 0

            img_half_raw = full_bg.crop((left, 0, left + crop_w, crop_h))

            # Letterbox Resize
            target_w, target_h = self.config.half_body_size
            ratio = min(target_w / crop_w, target_h / crop_h)
            new_w = int(crop_w * ratio)
            new_h = int(crop_h * ratio)
            img_half_resized = img_half_raw.resize(
                (new_w, new_h), Image.Resampling.LANCZOS
            )
            final_half = Image.new("RGB", (target_w, target_h), (255, 255, 255))
            final_half.paste(
                img_half_resized, ((target_w - new_w) // 2, (target_h - new_h) // 2)
            )

            half_name = f"{base_name}_{CropType.HALF.value}.jpg"
            final_half.save(output_dir / half_name, quality=95)
            results.append(
                ImageMeta(
                    half_name, char_name, label_id, CropType.HALF.value, str(img_path)
                )
            )

        except Exception as e:
            logger.error(f"âŒ Failed processing {img_path}: {e}")

        return results

    def run(
        self,
        raw_root: Union[str, Path],
        output_root: Union[str, Path],
        num_workers: int = 8,
    ) -> None:
        """
        ä¸»æ‰§è¡Œå…¥å£ (å¹¶è¡Œç‰ˆ)
        num_workers: å¹¶è¡Œæ•°é‡ï¼Œå»ºè®®è®¾ç½®ä¸º CPU æ ¸å¿ƒæ•° (ä½ çš„ 9700X å¯ä»¥è®¾ä¸º 8 æˆ– 16)
        """
        raw_path = Path(raw_root)
        out_path = Path(output_root)

        # å‡†å¤‡è¾“å‡ºç›®å½•
        img_out_path = out_path / "images"
        img_out_path.mkdir(parents=True, exist_ok=True)

        if not self.whitelist:
            raise ValueError("Whitelist is empty! Please call load_whitelist() first.")

        # 1. Scanning (æ‰«æé˜¶æ®µä¾ç„¶æ˜¯å¾ˆå¿«çš„ï¼Œå•çº¿ç¨‹å³å¯)
        logger.info(f"ğŸ” Scanning directory: {raw_path}...")
        tasks: List[Tuple[Path, str]] = []

        for root, _, files in os.walk(raw_path):
            if self._is_blacklisted(root):
                continue
            for file in files:
                file_path = Path(root) / file
                if file_path.suffix not in self.config.allowed_extensions:
                    continue
                if self._is_blacklisted(file):
                    continue

                char_name = self._match_character_name(file)
                if char_name:
                    tasks.append((file_path, char_name))

        logger.info(
            f"ğŸš€ Found {len(tasks)} valid images. Starting parallel processing with {num_workers} workers..."
        )

        # 2. Parallel Processing (å¹¶è¡Œå¤„ç†)
        all_meta: List[ImageMeta] = []

        # ä½¿ç”¨ ProcessPoolExecutor å¯åŠ¨å¤šè¿›ç¨‹
        with ProcessPoolExecutor(max_workers=num_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¼ é€’ self._process_single_imageï¼ŒPython ä¼šè‡ªåŠ¨åºåˆ—åŒ–å¯¹è±¡
            future_to_file = {
                executor.submit(self._process_single_image, p, img_out_path, name): p
                for p, name in tasks
            }

            # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦ï¼Œas_completed ä¼šåœ¨ä»»åŠ¡å®Œæˆæ—¶ç«‹åˆ»è¿”å›
            for future in tqdm(
                as_completed(future_to_file), total=len(tasks), desc="Processing"
            ):
                try:
                    meta_list = future.result()
                    all_meta.extend(meta_list)
                except Exception as e:
                    file_p = future_to_file[future]
                    logger.error(f"âŒ Worker failed processing {file_p}: {e}")

        # 3. Saving Metadata
        logger.info("ğŸ’¾ Saving metadata...")
        meta_dicts = [asdict(m) for m in all_meta]

        with open(out_path / "dataset.json", "w", encoding="utf-8") as f:
            json.dump(meta_dicts, f, indent=2, ensure_ascii=False)

        with open(out_path / "id_map.json", "w", encoding="utf-8") as f:
            json.dump(self.char_to_id, f, indent=2, ensure_ascii=False)

        logger.info(f"âœ¨ Preprocessing complete. Processed {len(all_meta)} items.")
