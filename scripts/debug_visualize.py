import torch
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import transforms
from little_diffusion.models import BabyUNet

# ================= é…ç½®åŒº =================
# ç¡®ä¿è¿™é‡Œå’Œä½ åˆšæ‰è·‘è¯Šæ–­è„šæœ¬æ—¶ç”¨çš„è·¯å¾„ä¸€æ¨¡ä¸€æ ·
IMG_PATH = "images/hutao.jpg"  
CKPT_PATH = "checkpoints/baby_unet.pth" 
# ========================================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def load_image_tensor(path, size=704):
    """åŠ è½½å›¾ç‰‡å¹¶å½’ä¸€åŒ–åˆ° [-1, 1]"""
    transform = transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    try:
        img = Image.open(path).convert('RGB')
        return transform(img).unsqueeze(0).to(device)
    except Exception as e:
        print(f"âŒ å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
        return None

def tensor_to_numpy_img(tensor):
    """æŠŠ [-1, 1] çš„ Tensor è½¬å› [0, 1] çš„ Numpy ç”¨äºç”»å›¾"""
    # tensor shape: (1, 3, H, W)
    img = (tensor[0] + 1) / 2
    img = img.clamp(0, 1)
    return img.permute(1, 2, 0).cpu().detach().numpy()

def main():
    print(f"ğŸ¨ å¼€å§‹å¯è§†åŒ–è¯Šæ–­...")
    
    # 1. å‡†å¤‡æ¨¡å‹
    model = BabyUNet(in_channels=3, out_channels=3, dim=64).to(device)
    try:
        state_dict = torch.load(CKPT_PATH, map_location=device)
        # å»å‰ç¼€é€»è¾‘
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith("_orig_mod."):
                new_state_dict[k[10:]] = v 
            else:
                new_state_dict[k] = v
        model.load_state_dict(new_state_dict, strict=True)
        print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    model.eval()

    # 2. å‡†å¤‡æ•°æ®
    x1 = load_image_tensor(IMG_PATH) # ç›®æ ‡å›¾ (Target)
    if x1 is None: return
    
    x0 = torch.randn_like(x1).to(device) # å™ªå£°å›¾ (Source)
    
    # 3. è¿™é‡Œçš„ t å¿…é¡»æ˜¯ä¸€æ ·çš„æ—¶é—´ç‚¹
    # æˆ‘ä»¬æµ‹è¯• t=0 çš„æƒ…å†µï¼Œæ¨¡å‹åº”è¯¥é¢„æµ‹ä»å™ªå£°ç›´æ¥èµ°åˆ°åŸå›¾çš„é€Ÿåº¦
    t = torch.zeros(1, 1).to(device) 

    print("ğŸ–¼ï¸ æ­£åœ¨è®¡ç®—...")

    # 4. è®©æ¨¡å‹é¢„æµ‹
    with torch.no_grad():
        # åœ¨ Flow Matching ä¸­ï¼Œv = x1 - x0
        # æ‰€ä»¥ç†è®ºä¸Š x1 = x0 + v
        pred_v = model(x0, t)
        
        # ã€å…³é”®ã€‘æ‰‹åŠ¨ä¸€æ­¥è¿˜åŸï¼
        # å¦‚æœæ¨¡å‹æ˜¯å¯¹çš„ï¼Œx0 åŠ ä¸Šé¢„æµ‹çš„é€Ÿåº¦ï¼Œå°±åº”è¯¥ç­‰äº x1 (åŸå›¾)
        x_reconstructed = x0 + pred_v 

    # 5. ç”»å›¾å¯¹æ¯”
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # å›¾1: çº¯å™ªå£°
    axes[0].imshow(tensor_to_numpy_img(x0))
    axes[0].set_title("Input: Noise (x0)")
    axes[0].axis('off')

    # å›¾2: ä½ çš„åŸå›¾ (æ£€æŸ¥è¿™ä¸€æ­¥ï¼)
    axes[1].imshow(tensor_to_numpy_img(x1))
    axes[1].set_title("Ground Truth: Reference Image (x1)")
    axes[1].axis('off')

    # å›¾3: æ¨¡å‹è¿˜åŸç»“æœ
    axes[2].imshow(tensor_to_numpy_img(x_reconstructed))
    axes[2].set_title("Model Prediction (x0 + pred_v)")
    axes[2].axis('off')

    plt.tight_layout()
    plt.show()
    
    # ä¿å­˜ç»“æœä»¥é˜² Notebook ä¸æ˜¾ç¤º
    plt.savefig("debug_result.png")
    print("âœ… ç»“æœå·²ä¿å­˜ä¸º debug_result.png")

if __name__ == "__main__":
    main()