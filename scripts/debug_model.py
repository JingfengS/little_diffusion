import torch
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms
from little_diffusion.models import BabyUNet

# ================= é…ç½®åŒº =================
# 1. è¿™é‡Œå¡«ä½ çœŸå®çš„å›¾ç‰‡è·¯å¾„ (å¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€æ ·)
IMG_PATH = "images/hutao.jpg"  
# 2. è¿™é‡Œå¡«ä½ åˆšæ‰çœ‹è¿‡çš„é‚£ä¸ª 14MB çš„æ¨¡å‹è·¯å¾„
CKPT_PATH = "checkpoints/baby_unet.pth" 
# ========================================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def load_image(path, size=704):
    """æ‰‹åŠ¨åŠ è½½å¹¶å½’ä¸€åŒ–å›¾ç‰‡ï¼Œæ¨¡æ‹Ÿ Dataset çš„è¡Œä¸º"""
    transform = transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # å½’ä¸€åŒ–åˆ° [-1, 1]
    ])
    try:
        img = Image.open(path).convert('RGB')
        return transform(img).unsqueeze(0).to(device) # (1, 3, 704, 704)
    except Exception as e:
        print(f"âŒ å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
        return None

def main():
    print(f"ğŸ•µï¸â€â™‚ï¸ å¼€å§‹æ¨¡å‹è¯Šæ–­...")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # 1. åˆå§‹åŒ–æ¨¡å‹
    model = BabyUNet(in_channels=3, out_channels=3, dim=64).to(device)

    # 2. åŠ è½½æƒé‡ (å¸¦å‰ç¼€ä¿®å¤é€»è¾‘)
    try:
        state_dict = torch.load(CKPT_PATH, map_location=device)
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith("_orig_mod."):
                new_state_dict[k[10:]] = v
            else:
                new_state_dict[k] = v
        
        # strict=True æ˜¯å…³é”®ï¼å¦‚æœ key ä¸åŒ¹é…å®ƒä¼šç«‹åˆ»æŠ¥é”™ï¼Œè€Œä¸æ˜¯é»˜é»˜è£…æ­»
        model.load_state_dict(new_state_dict, strict=True)
        print(f"âœ… æƒé‡åŠ è½½æˆåŠŸ: {CKPT_PATH}")
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½æå…¶å¤±è´¥: {e}")
        return

    model.eval() # å¼€å¯è¯„ä¼°æ¨¡å¼

    # 3. å‡†å¤‡æ•°æ®
    x1 = load_image(IMG_PATH) # ç›®æ ‡å›¾ç‰‡ (çœŸå®å›¾ç‰‡)
    if x1 is None: return
    
    # æ„é€ éšæœºå™ªå£° x0
    x0 = torch.randn_like(x1).to(device)
    
    # æ„é€ æ—¶é—´ t (æˆ‘ä»¬æµ‹è¯• t=0.5 çš„ä¸­é—´æ—¶åˆ»)
    t = torch.tensor([[0.5]]).to(device) # (1, 1)

    # 4. æ‰‹åŠ¨è®¡ç®— Flow Matching ç›®æ ‡
    # çº¿æ€§æ’å€¼: xt = 0.5 * x0 + 0.5 * x1
    xt = (1 - t) * x0 + t * x1
    
    # çœŸå®é€Ÿåº¦ç›®æ ‡: v = x1 - x0
    target_v = x1 - x0

    print("\nğŸ“Š --- è¯Šæ–­æŠ¥å‘Š ---")
    
    # 5. æ¨¡å‹é¢„æµ‹
    with torch.no_grad():
        pred_v = model(xt, t)
    
    # 6. è®¡ç®— Loss
    loss = F.mse_loss(pred_v, target_v)
    
    print(f"ğŸ”¹ ç›®æ ‡é€Ÿåº¦ (Target v) å‡å€¼: {target_v.mean().item():.4f}, æ ‡å‡†å·®: {target_v.std().item():.4f}")
    print(f"ğŸ”¹ é¢„æµ‹é€Ÿåº¦ (Pred v)   å‡å€¼: {pred_v.mean().item():.4f}, æ ‡å‡†å·®: {pred_v.std().item():.4f}")
    print(f"ğŸ“‰ å½“å‰ Loss (MSE): {loss.item():.6f}")

    # 7. åˆ¤å®šç»“æœ
    if loss.item() < 0.05:
        print("\nâœ… ç»“è®º: æ¨¡å‹æ˜¯ä¸ªå¤©æ‰ï¼æƒé‡å®Œå…¨æ²¡é—®é¢˜ã€‚")
        print("ğŸ‘‰ é—®é¢˜å‡ºåœ¨é‡‡æ ·è„šæœ¬ (sample_hutao.py) çš„ç§¯åˆ†é€»è¾‘ä¸Šï¼Œæˆ–è€…å¯è§†åŒ–ä»£ç ä¸Šã€‚")
    else:
        print("\nâŒ ç»“è®º: æ¨¡å‹æ˜¯ä¸ªç¬¨è›‹ã€‚æƒé‡åŠ è½½è¿›å»äº†ï¼Œä½†å®ƒé¢„æµ‹å…¨æ˜¯é”™çš„ã€‚")
        print("ğŸ‘‰ è¿™ä¸ª .pth æ–‡ä»¶å¯èƒ½æ˜¯ä¸€ä¸ªæ²¡è®­ç»ƒè¿‡çš„åˆå§‹æƒé‡ï¼Œæˆ–è€…è®­ç»ƒæ—¶ä¿å­˜é€»è¾‘æœ‰é—®é¢˜ã€‚")

if __name__ == "__main__":
    main()