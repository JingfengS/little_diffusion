import argparse
import torch
import logging
import time
from pathlib import Path

import sys
sys.path.append(str(Path(__file__).parent.parent / "src"))
from little_diffusion.models.config import DiTConfig
from little_diffusion.models.dit import DiT
from little_diffusion.processor import VAEProcessor

# å¼•å…¥ä½ çš„ Core æ¡†æ¶ï¼
from little_diffusion.core import ODE, EulerSimulator

# ================= ğŸ”§ é…ç½® =================
torch.set_float32_matmul_precision('high')
logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')
logger = logging.getLogger(__name__)

# ================= ğŸ§  Adapter: DiT ä¸“ç”¨çš„ ODE =================
class DiTODE(ODE):
    """é€‚é…å™¨ï¼šå°† DiT åŒ…è£…æˆç¬¦åˆ core.py æ ‡å‡†çš„ ODE å¯¹è±¡"""
    def __init__(self, model, label_id, null_label_id, cfg_scale):
        self.model = model
        self.label_tensor = torch.tensor([label_id], device=next(model.parameters()).device)
        self.null_tensor = torch.tensor([null_label_id], device=self.label_tensor.device)
        self.cfg_scale = cfg_scale

    def drift_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
        # t ä¼ è¿›æ¥çš„æ˜¯å½¢çŠ¶ä¸º (1, 1) æˆ– (1) çš„æµ®ç‚¹æ•° [0, 1]
        t_float = t.view(-1)
        # æ˜ å°„ç»™ DiT
        t_int = (t_float * 1000).long()

        # æ‰§è¡Œå¸¦æœ‰ CFG çš„å‰å‘ä¼ æ’­
        eps_cond = self.model(xt, t_int, self.label_tensor)
        if self.cfg_scale > 1.0:
            eps_uncond = self.model(xt, t_int, self.null_tensor)
            v_pred = eps_uncond + self.cfg_scale * (eps_cond - eps_uncond)
        else:
            v_pred = eps_cond
            
        return v_pred

# ================= ğŸƒ ä¸»å‡½æ•° =================
def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--ckpt", type=str, required=True)
    parser.add_argument("--steps", type=int, default=50)
    parser.add_argument("--cfg_scale", type=float, default=2.0)
    parser.add_argument("--label", type=int, default=0)
    return parser.parse_args()

def main():
    args = get_args()
    device = torch.device("cuda")
    
    # 1. åŠ è½½æ¨¡å‹ (ä»£ç ç•¥ï¼Œä¸ä¹‹å‰ä¸€æ ·åŠ è½½ .pth å’Œ config)
    checkpoint = torch.load(args.ckpt, map_location=device)
    config = DiTConfig(**checkpoint['config'])
    model = DiT(config).to(device)
    
    new_state_dict = {k.replace("_orig_mod.", ""): v for k, v in checkpoint['model_state_dict'].items()}
    model.load_state_dict(new_state_dict)
    model.eval()
    
    vae = VAEProcessor(device=device, use_fp16=True)

    # 2. å‡†å¤‡ ODE å’Œ é‡‡æ ·å™¨
    logger.info("ğŸš€ Starting Generation using Core Framework...")
    null_class = config.num_classes - 1
    
    # ğŸŒŸ å®ä¾‹åŒ–ä½ çš„ OOP æ¡†æ¶ç»„ä»¶ï¼
    ode = DiTODE(model, args.label, null_class, args.cfg_scale)
    simulator = EulerSimulator(ode)

    # 3. å‡†å¤‡æ—¶é—´è½´å’Œåˆå§‹çŠ¶æ€
    # Flow Matching ä» t=0 (çº¯å™ªå£°) èµ°åˆ° t=1 (åŸå›¾)
    ts = torch.linspace(0.0, 1.0, args.steps + 1, device=device).view(1, -1, 1)
    x0 = torch.randn(1, config.in_channels, config.input_size, config.input_size, device=device)

    # 4. æ‰§è¡Œæ¨¡æ‹Ÿ
    start_time = time.time()
    with torch.no_grad():
        with torch.amp.autocast('cuda', dtype=torch.bfloat16):
            # ç›´æ¥è°ƒç”¨ simulateï¼Œå®ƒä¼šè¿”å›æœ€åä¸€æ­¥çš„ç»“æœ
            x_final = simulator.simulate(x0, ts)

    logger.info(f"âš¡ Generation took {time.time() - start_time:.2f}s")
    logger.info(f"ğŸ“Š Latent Stats: Mean={x_final.mean():.2f}, Std={x_final.std():.2f}")

    # 5. è§£ç å¹¶ä¿å­˜
    images = vae.decode(x_final)
    images[0].save(f"images/core_sample_label{args.label}.png")
    logger.info("ğŸ† Success!")

if __name__ == "__main__":
    main()