import argparse
import torch
import logging
import time
import numpy as np
from pathlib import Path
from PIL import Image

# Â§çÁî®Êàë‰ª¨ÂÜôÂ•ΩÁöÑÊ®°Âùó
from little_diffusion.models import BabyUNet
from little_diffusion.core import ODE, EulerSimulator
from little_diffusion.processor import VAEProcessor

# ================= üîß ÈÖçÁΩÆ =================
# ÈíàÂØπ 5070 Ti ÂºÄÂêØ TF32
torch.set_float32_matmul_precision('high')

logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')
logger = logging.getLogger(__name__)

# ================= üß† Á•ûÁªè ODE ÂåÖË£ÖÂô® =================
class NeuralODE(ODE):
    def __init__(self, model: torch.nn.Module, cfg_scale: float = 1.0):
        super().__init__()
        self.model = model
        self.cfg_scale = cfg_scale # ËôΩÁÑ∂Áé∞Âú®ÊòØÂçïÂõæËøáÊãüÂêàÔºåÈ¢ÑÁïô CFG Êé•Âè£

    def drift_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
        # Á°Æ‰øù t ÁöÑÂΩ¢Áä∂Ê≠£Á°Æ (Batch, 1)
        if t.dim() == 0:
            t = t.view(1, 1).expand(xt.shape[0], 1)
        elif t.dim() == 1:
            t = t.view(-1, 1)
            
        # È¢ÑÊµãÈÄüÂ∫¶Âú∫ v
        # Â¶ÇÊûúËÆ≠ÁªÉÁî®‰∫Ü label embedding ËøôÈáåÂèØ‰ª•ÂÅö guidanceÔºåÁé∞Âú®Áõ¥Êé•È¢ÑÊµã
        v_pred = self.model(xt, t)
        
        return v_pred

def get_args():
    parser = argparse.ArgumentParser(description="üé® Industrial Flow Matching Sampler")
    parser.add_argument("--ckpt", type=str, required=True, help="Path to checkpoint (.pth)")
    parser.add_argument("--save_dir", type=str, default="./images/save_images", help="Output directory")
    parser.add_argument("--size", type=int, default=704, help="Output image size (pixel)")
    parser.add_argument("--steps", type=int, default=50, help="ODE solver steps (20-100)")
    parser.add_argument("--seed", type=int, default=None, help="Random seed")
    parser.add_argument("--dim", type=int, default=128, help="Model hidden dimension (Must match training!)")
    parser.add_argument("--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu")
    return parser.parse_args()

def main():
    args = get_args()
    device = torch.device(args.device)
    
    # 1. ËÆæÁΩÆÈöèÊú∫ÁßçÂ≠ê (‰∏∫‰∫ÜÂ§çÁé∞ÈÇ£Âº†ÊúÄÂ•ΩÁöÑÂõæ)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        logger.info(f"üå± Seed set to: {args.seed}")
    
    # 2. ÂàùÂßãÂåñ VAE Â§ÑÁêÜÂô® (Ëß£Á†ÅÁî®)
    # Ëá™Âä®‰ΩøÁî® FP16 Âä†ÈÄü
    vae_processor = VAEProcessor(device=args.device, use_fp16=True)

    # 3. Âä†ËΩΩ UNet Ê®°Âûã
    logger.info(f"üß† Loading Model from {args.ckpt}...")
    model = BabyUNet(in_channels=4, out_channels=4, dim=args.dim).to(device)
    
    try:
        checkpoint = torch.load(args.ckpt, map_location=device)
        state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
        
        # üõ†Ô∏è È≤ÅÊ£íÊÄß‰øÆÂ§çÔºöËá™Âä®ÂéªÈô§ _orig_mod ÂâçÁºÄ
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith("_orig_mod."):
                new_state_dict[k[10:]] = v
            else:
                new_state_dict[k] = v
        
        model.load_state_dict(new_state_dict)
        model.eval()
        # ÂÜçÊ¨°ÂºÄÂêØÁºñËØëÂä†ÈÄüÊé®ÁêÜ (ÂèØÈÄâ)
        # model = torch.compile(model, mode="max-autotune") 
        logger.info("‚úÖ Model loaded successfully!")
    except Exception as e:
        logger.error(f"‚ùå Failed to load model: {e}")
        return

    # 4. ÈááÊ†∑ÊµÅÁ®ã
    logger.info(f"üé® Generating image ({args.size}x{args.size})... Steps: {args.steps}")
    
    # ËÆ°ÁÆó Latent Â∞∫ÂØ∏ (704 -> 88)
    latent_size = args.size // 8
    
    # ÂàùÂßãÂåñÂô™Â£∞ x0 (Batch=1, Channels=4, H, W)
    x0 = torch.randn(1, 4, latent_size, latent_size).to(device)
    
    # Êó∂Èó¥Ê≠•Èïø (0 -> 1)
    ts = torch.linspace(0, 1, args.steps, device=device).view(1, -1, 1)
    
    ode = NeuralODE(model)
    simulator = EulerSimulator(ode)

    start_time = time.time()

    with torch.no_grad():
        # üî• ÂºÄÂêØ AMP Ê∑∑ÂêàÁ≤æÂ∫¶Êé®ÁêÜ (5070 Ti Ê†∏ÂøÉÂä†ÈÄü)
        with torch.amp.autocast('cuda'):
            # ÊâßË°å ODE ÁßØÂàÜ
            # ËøôÈáåÁöÑ simulate ‰ºöË∞ÉÁî® stepÔºå‰ªé x0 (Âô™Â£∞) Ëµ∞Âà∞ x1 (Êï∞ÊçÆ)
            traj = simulator.simulate_with_trajectory(x0, ts)
            
            # ÂèñÊúÄÂêé‰∏ÄÊ≠•ÁöÑÁªìÊûú
            x_final = traj[:, -1] # (1, 4, 88, 88)

    gen_time = time.time() - start_time
    logger.info(f"‚ö° Generation took {gen_time:.3f}s")

    # 5. Ëß£Á†Å Latent -> Pixel
    logger.info("üß© Decoding Latent to Image...")
    # VAE Processor ÂÜÖÈÉ®‰ºöËá™Âä®Â§ÑÁêÜ scaling factor ÂíåÊï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢
    images = vae_processor.decode(x_final)

    # 6. ‰øùÂ≠òÁªìÊûú
    save_path = Path(args.save_dir)
    save_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = save_path / f"sample_{timestamp}_s{args.steps}.png"
    
    images[0].save(filename)
    logger.info(f"üíæ Saved to: {filename}")
    
    # È°∫‰æøÊâìÂç∞‰∏Ä‰∏ã Latent ÁöÑÁªüËÆ°‰ø°ÊÅØÔºåÁúãÁúãÊòØ‰∏çÊòØ‚ÄúÁÇ∏‚Äù‰∫Ü
    logger.info(f"üìä Latent Stats: Mean={x_final.mean():.4f}, Std={x_final.std():.4f}, Min={x_final.min():.4f}, Max={x_final.max():.4f}")
    if x_final.std() > 5.0 or x_final.abs().max() > 10.0:
         logger.warning("‚ö†Ô∏è Warning: Latent values seem very high! The image might be noisy.")

if __name__ == "__main__":
    main()