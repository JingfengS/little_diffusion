import torch
import argparse
import logging
import sys
import random
from pathlib import Path
from PIL import Image

# ç¡®ä¿èƒ½å¯¼å…¥ src
sys.path.append(str(Path(__file__).parent.parent / "src"))

from little_diffusion.processor import VAEProcessor

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    parser = argparse.ArgumentParser(description="Inspect Latents by Decoding them back to Pixels")
    parser.add_argument("--pt_file", type=str, default="data/processed/latents.pt", help="Path to .pt file")
    parser.add_argument("--output_dir", type=str, default="data/processed/inspection", help="Where to save decoded images")
    parser.add_argument("--num_samples", type=int, default=10, help="How many random samples to check")
    parser.add_argument("--vae", type=str, default="madebyollin/sdxl-vae-fp16-fix", help="VAE model name (Must match preparation!)")
    
    args = parser.parse_args()
    
    out_dir = Path(args.output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. åŠ è½½ Latents æ–‡ä»¶
    if not Path(args.pt_file).exists():
        logger.error(f"âŒ Latent file not found: {args.pt_file}")
        return

    logger.info(f"ðŸ“¦ Loading {args.pt_file}...")
    data = torch.load(args.pt_file, map_location="cpu")
    
    # å…¼å®¹å¤„ç†ï¼šæ£€æŸ¥æ˜¯æ–°ç‰ˆ Dict æ ¼å¼è¿˜æ˜¯æ—§ç‰ˆ Tensor æ ¼å¼
    if isinstance(data, dict):
        latents = data['latents']
        labels = data['labels']
        # ä¼˜å…ˆä½¿ç”¨æ–‡ä»¶é‡Œè®°å½•çš„ scaling factorï¼Œå¦‚æžœæ²¡æœ‰åˆ™ç”¨ SDXL é»˜è®¤å€¼
        scaling_factor = data.get('scaling_factor', 0.13025)
        logger.info(f"   -> Found metadata. Scaling Factor: {scaling_factor}")
    else:
        latents = data
        labels = None
        scaling_factor = 0.13025 # å‡è®¾æ˜¯ SDXL
        logger.warning("âš ï¸ Legacy tensor format detected. Assuming SDXL scaling factor.")
        
    total_imgs = len(latents)
    logger.info(f"ðŸ“Š Dataset Stats: {total_imgs} images, Latent Shape: {latents.shape[1:]}")
    
    # 2. éšæœºæŠ½æ ·
    indices = random.sample(range(total_imgs), min(args.num_samples, total_imgs))
    selected_latents = latents[indices]
    selected_labels = labels[indices] if labels is not None else None
    
    # 3. åˆå§‹åŒ– VAE è§£ç å™¨
    logger.info(f"ðŸš€ Loading VAE: {args.vae}...")
    processor = VAEProcessor(model_name=args.vae, scaling_factor=scaling_factor)
    
    # 4. è§£ç  (Latent -> Pixel)
    logger.info("ðŸŽ¨ Decoding latents...")
    decoded_images = processor.decode(selected_latents)
    
    # 5. ä¿å­˜ç»“æžœ
    logger.info(f"ðŸ’¾ Saving inspections to {out_dir}...")
    for i, (idx, img) in enumerate(zip(indices, decoded_images)):
        label_info = f"_class{selected_labels[i].item()}" if selected_labels is not None else ""
        save_name = f"inspect_{i:02d}_idx{idx}{label_info}.png"
        img.save(out_dir / save_name)
        logger.info(f"   -> Saved {save_name}")
        
    logger.info("âœ… Done! Go check the images.")

if __name__ == "__main__":
    main()